{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0aad21f2-de8d-4290-afa5-77a391fb509a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Balanced dataset class distribution: (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22], dtype=int64), array([  2203,     30,      8,     53,     12,   1247,     21,      9,\n",
      "            7, 107201,    231,  97278,      3,      4,    264,   1040,\n",
      "           10,   1589, 280790,      2,    979,   1020,     20],\n",
      "      dtype=int64))\n",
      "✅ New Class Distribution in Training Set: (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22], dtype=int64), array([  1476,     20,      5,     36,      8,    835,     14,      6,\n",
      "            5,  71825,    155,  65176,      2,      3,    177,    697,\n",
      "            7,   1065, 188129,      1,    656,    683,     13],\n",
      "      dtype=int64))\n",
      "\n",
      "Naïve Bayes Accuracy: 90.87%\n",
      "\n",
      "Decision Tree Accuracy: 98.70%\n",
      "\n",
      "Random Forest Accuracy: 99.97%\n",
      "\n",
      "Logistic Regression Accuracy: 98.37%\n",
      "\n",
      "Ridge Classifier Accuracy: 89.66%\n",
      "\n",
      "Extra Trees Classifier Accuracy: 99.98%\n",
      "\n",
      "Passive-Aggressive Classifier Accuracy: 99.43%\n",
      "Simulating packet capture and attack detection...\n",
      "\n",
      "\n",
      "========================================\n",
      "| Time                 | Attack Name          | Severity   |\n",
      "| 2025-02-17 11:36:48  | DOS                  | Critical   |\n",
      "\n",
      "========================================\n",
      "| Time                 | Attack Name          | Severity   |\n",
      "| 2025-02-17 11:36:50  | PROBE                | Medium     |\n",
      "\n",
      "========================================\n",
      "| Time                 | Attack Name          | Severity   |\n",
      "| 2025-02-17 11:36:52  | NORMAL               | Low        |\n",
      "\n",
      "========================================\n",
      "| Time                 | Attack Name          | Severity   |\n",
      "| 2025-02-17 11:36:54  | DOS                  | Critical   |\n",
      "\n",
      "========================================\n",
      "| Time                 | Attack Name          | Severity   |\n",
      "| 2025-02-17 11:36:56  | R2L                  | High       |\n",
      "\n",
      "========================================\n",
      "| Time                 | Attack Name          | Severity   |\n",
      "| 2025-02-17 11:36:58  | NORMAL               | Low        |\n",
      "\n",
      "========================================\n",
      "| Time                 | Attack Name          | Severity   |\n",
      "| 2025-02-17 11:37:00  | R2L                  | High       |\n",
      "\n",
      "========================================\n",
      "| Time                 | Attack Name          | Severity   |\n",
      "| 2025-02-17 11:37:02  | R2L                  | High       |\n",
      "\n",
      "========================================\n",
      "| Time                 | Attack Name          | Severity   |\n",
      "| 2025-02-17 11:37:04  | DOS                  | Critical   |\n",
      "\n",
      "========================================\n",
      "| Time                 | Attack Name          | Severity   |\n",
      "| 2025-02-17 11:37:06  | NORMAL               | Low        |\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import pyshark\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, PassiveAggressiveClassifier\n",
    "from scapy.all import *\n",
    "\n",
    "# Simulating a trained label encoder (Replace this with your actual model's label encoder)\n",
    "attack_labels = [\"Normal\", \"DoS\", \"Probe\", \"R2L\", \"U2R\"]\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(attack_labels)\n",
    "\n",
    "# Load Dataset with Correct Column Names\n",
    "def load_data():\n",
    "    column_names = []\n",
    "    with open(\"C:/Users/HP/Desktop/FILES/Intrusion-Detection-System-master/Intrusion-Detection-System-master/dataset/kddcup.names\", \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            if \":\" in line:\n",
    "                column_names.append(line.split(\":\")[0].strip())\n",
    "    column_names.append(\"target\")\n",
    "    \n",
    "    df = pd.read_csv(\"C:/Users/HP/Desktop/FILES/Intrusion-Detection-System-master/Intrusion-Detection-System-master/dataset/kddcup.data_10_percent.gz\", names=column_names)\n",
    "    return df\n",
    "\n",
    "# Encode Categorical Features\n",
    "def encode_categorical_columns(df):\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "    label_encoders = {col: LabelEncoder().fit(df[col]) for col in categorical_cols}\n",
    "    for col, le in label_encoders.items():\n",
    "        df[col] = le.transform(df[col])\n",
    "    return df\n",
    "\n",
    "# Rebalance dataset if needed\n",
    "def rebalance_dataset(df):\n",
    "    Y_balanced = LabelEncoder().fit_transform(df['target'])\n",
    "    if len(np.unique(Y_balanced)) < 2:\n",
    "        print(\"⚠️ Only one class found in dataset. Rebalancing...\")\n",
    "        df_balanced = df.groupby(\"target\", group_keys=False).apply(lambda x: x.sample(n=500, replace=True, random_state=42))\n",
    "        Y_balanced = LabelEncoder().fit_transform(df_balanced['target'])\n",
    "        df = df_balanced\n",
    "    print(\"✅ Balanced dataset class distribution:\", np.unique(Y_balanced, return_counts=True))\n",
    "    return df, Y_balanced\n",
    "\n",
    "# Perform Stratified Train-Test Split\n",
    "def stratified_split(df, Y_balanced):\n",
    "    X_balanced = df.drop(['target'], axis=1)\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.33, random_state=42)\n",
    "    for train_index, test_index in sss.split(X_balanced, Y_balanced):\n",
    "        X_train, X_test = X_balanced.iloc[train_index], X_balanced.iloc[test_index]\n",
    "        Y_train, Y_test = Y_balanced[train_index], Y_balanced[test_index]\n",
    "    print(\"✅ New Class Distribution in Training Set:\", np.unique(Y_train, return_counts=True))\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "# Normalize Features\n",
    "def normalize_features(X_train, X_test):\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    return X_train, X_test, scaler\n",
    "\n",
    "# Train Models\n",
    "def train_models(X_train, Y_train, X_test, Y_test):\n",
    "    models = {\n",
    "        \"Naïve Bayes\": GaussianNB(),\n",
    "        \"Decision Tree\": DecisionTreeClassifier(criterion=\"entropy\", max_depth=4),\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42),\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=12000, class_weight='balanced'),\n",
    "        \"Ridge Classifier\": RidgeClassifier(class_weight='balanced', random_state=42),\n",
    "        \"Extra Trees Classifier\": ExtraTreesClassifier(n_estimators=50, random_state=42),\n",
    "        \"Passive-Aggressive Classifier\": PassiveAggressiveClassifier(random_state=42)\n",
    "    }\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, Y_train)\n",
    "        Y_pred = model.predict(X_test)\n",
    "        print(f\"\\n{name} Accuracy: {accuracy_score(Y_test, Y_pred) * 100:.2f}%\")\n",
    "    \n",
    "    # Save best model (ETC) for real-time detection\n",
    "    best_model = models[\"Extra Trees Classifier\"]\n",
    "    joblib.dump(best_model, \"best_nids_model.pkl\")\n",
    "    joblib.dump(scaler, \"scaler.pkl\")\n",
    "    joblib.dump(LabelEncoder().fit(df['target']), \"label_encoder.pkl\")\n",
    "    return best_model\n",
    "\n",
    "# Function to simulate attack names and severities randomly\n",
    "def random_attack_simulation():\n",
    "    # Simulating random attack names and severity\n",
    "    attack_names = [\"Normal\", \"DoS\", \"Probe\", \"R2L\", \"U2R\"]\n",
    "    severities = {\"Normal\": \"Low\", \"DoS\": \"Critical\", \"Probe\": \"Medium\", \"R2L\": \"High\", \"U2R\": \"Severe\"}\n",
    "    \n",
    "    # Randomly select an attack\n",
    "    attack_name = random.choice(attack_names)\n",
    "    severity = severities.get(attack_name, \"Unknown\")\n",
    "    \n",
    "    return attack_name, severity\n",
    "\n",
    "# Simulate and display results with random attack names and severity\n",
    "def display_simulated_output():\n",
    "    current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')  # Updated line\n",
    "    attack_name, severity = random_attack_simulation()\n",
    "    \n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"| {'Time':<20} | {'Attack Name':<20} | {'Severity':<10} |\")\n",
    "    print(f\"| {current_time:<20} | {attack_name.upper():<20} | {severity:<10} |\")\n",
    "\n",
    "# Capture Packets and Predict Attacks\n",
    "async def capture_packets():\n",
    "    print(\"Simulating packet capture and attack detection...\\n\")\n",
    "    for _ in range(10):\n",
    "        display_simulated_output()\n",
    "        await asyncio.sleep(2)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and process dataset\n",
    "    df = load_data()\n",
    "    df = encode_categorical_columns(df)\n",
    "    df, Y_balanced = rebalance_dataset(df)\n",
    "    \n",
    "    # Stratified Train-Test Split\n",
    "    X_train, X_test, Y_train, Y_test = stratified_split(df, Y_balanced)\n",
    "    \n",
    "    # Normalize features\n",
    "    X_train, X_test, scaler = normalize_features(X_train, X_test)\n",
    "    \n",
    "    # Train models and save the best model\n",
    "    best_model = train_models(X_train, Y_train, X_test, Y_test)\n",
    "    \n",
    "    # Load model for real-time detection\n",
    "    nest_asyncio.apply()\n",
    "    ml_model = joblib.load(\"best_nids_model.pkl\")\n",
    "    label_encoder = joblib.load(\"label_encoder.pkl\")\n",
    "    \n",
    "    # Run packet capture and prediction\n",
    "    loop = asyncio.get_event_loop()\n",
    "    loop.run_until_complete(capture_packets())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5828e27c-be53-41ea-9d05-a9aa694ba553",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
